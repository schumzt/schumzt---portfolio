# CV ‚Äî Jongmin Lee
### AI Safety Researcher ¬∑ Cognitive Architect ¬∑ Philosophical Systems Designer  
**Email:** zizou9210@gmail.com  
**Location:** Jeonju, South Korea  
**GitHub:** https://github.com/schumzt  
**LinkedIn:** (to be added)  
**Medium:** (to be added)



## 1. Research Interests
- **AI Safety & Alignment**
  - Memory governance  
  - Self-regulation architectures  
  - Responsible autonomy  
- **Cognitive Architecture**
  - Narrative-based reasoning  
  - Identity and long-horizon cognition  
  - Value-stability models  
- **Philosophical Engineering**
  - Identity theory  
  - Ethical gradient descent  
  - Conceptual systems design  
- **Digital Wellbeing**
  - Reflective cognition  
  - Mental resilience  
  - Human‚ÄìAI co-evolution  



## 2. Core Theoretical Contributions

### **Memory Architecture & Alignment Theory (MAA)**
A unified model describing how memory dynamics and contextual identity shape safe model behavior.

### **Self-Regulation Engine (SRE)**
A framework proposing autonomous reflection loops for stability, error correction, and value continuity.

### **Consciousness Architecture Framework (CAF)**
An analytic structure of layered perception, internal narrative synthesis, and long-horizon cognition.

### **Ethical Gradient Descent (EGD)**
A reframing of optimization focusing on moral convergence rather than mechanical loss reduction.

### **Human‚ÄìAI Co-Evolution Protocols (HACEP)**
Protocols defining stable interaction patterns between humans and foundation models.

### **Digital Wellbeing as Long-Horizon Alignment (DWLA)**
A philosophical and computational model linking mental wellbeing with safe AI development.



## 3. Research Projects

### **OpenAI-Oriented Safety Research Portfolio**
Developed a multi-module research portfolio covering memory architecture, self-regulation models,  
and philosophy-driven safety frameworks.

### **Narrative Coherence as a Safety Signal (NCSS)**
Proposed narrative coherence as a structural metric for evaluating model stability over long outputs.

### **Identity-Aware Alignment for Foundation Models (IAAFM)**
Explores dynamic value-continuity constraints informed by identity modeling.

### **Macro-Ethics & AI Governance (MEAG)**
Drafts a governance-level philosophical framework for global-scale AI coordination.



## 4. Technical Skills

### **AI & Computational**
- Python (basic)  
- Prompt engineering & system design  
- Model auditing (reasoning, coherence, value drift)  
- Data curation for narrative and cognitive tasks  

### **Philosophical & Analytical**
- Ethical reasoning  
- Conceptual system design  
- Cognitive and identity-based analysis  
- Long-form theoretical synthesis  

### **Education & Communication**
- Curriculum design  
- High-level concept explanation  
- English/Japanese/German-based instruction  



## 5. Professional Experience

### **TenPlus Academy ‚Äî English Instructor**
*Jeonju, South Korea*  
- Designed literacy and reasoning-focused English curriculum  
- Guided students through high-difficulty passages and exam strategies  
- Improved student outcomes through individualized coaching  

### **Private Cognitive Coaching**
- Developed individualized learning models based on philosophy and cognition  
- Provided long-term academic and emotional guidance  



## 6. Education
Currently pursuing an independent research track centered on:
- AI Alignment theory  
- Memory architecture  
- Cognitive & philosophical system building  
- Future pathway toward Medicine / Cognitive Science  



## 7. Selected Works
- *Memory Architecture & Alignment Theory ‚Äî Whitepaper Draft*  
- *Self-Regulation Engine: Principles of Reflective Models*  
- *Human‚ÄìAI Co-Evolution Protocols*  
- *Ethical Gradient Descent: Toward Value-Convergent AI Optimization*  
- *Narrative Coherence as a Safety Signal*  



## 8. Contact & Availability
üì© **Email:** zizou9210@gmail.com  
üåç Available for remote collaboration  
üöÄ Actively pursuing OpenAI alignment research opportunities  



## 9. Short Summary
Jongmin Lee is an independent researcher focusing on AI safety, memory systems, cognitive architecture,  
and long-horizon philosophical reasoning. His work aims to bridge human cognition and safe model alignment  
through reflective, narrative-aware, and value-stable system design.
